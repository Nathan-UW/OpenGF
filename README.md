# OpenGF: An Ultra-Large-Scale Ground Filtering Dataset Built Upon Open ALS Point Clouds Around the World
[![arXiv](https://img.shields.io/badge/arXiv-2101.09641-b31b1b.svg)](https://arxiv.org/abs/2101.09641)

**OpenGF: An Ultra-Large-Scale Ground Filtering Dataset Built Upon Open ALS Point Clouds Around the World**
Nannan Qin, Weikai Tan, Lingfei Ma, Dedong Zhang, Jonathan Li*

**[[Paper](https://arxiv.org/abs/2101.09641)] [[Homepage](https://uwaterloo.ca/geospatial-sensing/)][[Download]()]**

OpenGF is an Ultra-Large-Scale Ground Filtering dataset covering over 47 km<sup>2</sup> built upon open ALS point clouds of 4 different countries around the world. It not only includes more than half a billion finely labeled ground and non-ground points, but also contains 9 different terrain scenes. 
The dataset will be released at Google Drive and 百度网盘 soon. **Currently, we are testing the dataset again to make sure there are no problems in our release version**

An example of OpenGF
![img](Imgs/figexample.png)

Typical samples belonging to 9 different terrain scenes
![img](Imgs/figsample.png)

Challenging areas of Test I
![img](Imgs/figtest1.png)

Challenging areas of Test II
![img](Imgs/figtest2.png)

The data source of OpenGF comes from [AHN3](https://downloads.pdok.nl/ahn3-downloadpage/), [Opentopography](https://portal.opentopography.org/datasets), and [Ontario Point Cloud](https://geohub.lio.gov.on.ca/datasets/adf19376eecd4440a4579a73abe490f5).

## Citation

If it is helpful for your work, please consider citing our paper:

    @article{qin2021opengf,
        title = {OpenGF: An Ultra-Large-Scale Ground Filtering Dataset Built Upon Open ALS Point Clouds Around the World},
        author = {Qin, Nannan and Tan, Weikai and Ma, Lingfei and Zhang, Dedong and Li, Jonathan},
        booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops},
        year = {2021}
    }

### Updates
* 08/04/2021: The OpenGF has been accepted by CVPRW 2021!


## Related projects
1. [3D-Terrain-Recognition: Deep fusion of multi-view and multimodal representation of ALS point cloud for 3D terrain scene recognition](https://github.com/Nathan-UW/3D-Terrain-Recognition) ![GitHub stars](https://img.shields.io/github/stars/Nathan-UW/3D-Terrain-Recognition.svg?style=flat&label=Star)
2. [VPNet-CRF: Semantic Labeling of ALS Point Cloud via Learning Voxel and Pixel Representations](https://github.com/Nathan-UW/VPNet) ![GitHub stars](https://img.shields.io/github/stars/Nathan-UW/VPNet.svg?style=flat&label=Star)
4. [Toronto-3D: A Large-scale Mobile LiDAR Dataset for Semantic Segmentation of Urban Roadways](https://github.com/WeikaiTan/Toronto-3D) ![Github](https://img.shields.io/github/stars/WeikaiTan/Toronto-3D.svg?style=flat&label=Star)

